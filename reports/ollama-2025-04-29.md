# Daily Progress Report: ollama/ollama (2025-04-29)

## 🐛 Open Issues
- [what is the endpoint of rerank](https://github.com/ollama/ollama/issues/10467) by JonSmall
- [Website Issue Firefox Model Listing](https://github.com/ollama/ollama/issues/10464) by duckfriend123
- [all model can not run when added QWEN3:32b](https://github.com/ollama/ollama/issues/10463) by honhwa
- [how to run ollama model on CPU instead of GPU even the GPU is available?](https://github.com/ollama/ollama/issues/10462) by Bob123Yang
- [Support Issue of some Qwen3 Series](https://github.com/ollama/ollama/issues/10459) by xuanzhec
- [Qwen3 MoE 30b-a3b, poor performance and Low GPU utilization issue](https://github.com/ollama/ollama/issues/10458) by vYLQs6
- [Can enable_thinking parameter be adjusted by passing a map through environment variables?](https://github.com/ollama/ollama/issues/10457) by utopeadia
- [how can i disable thinking mode?](https://github.com/ollama/ollama/issues/10456) by codeMonkey-shin
- [Linux system reports an error when running version 0.6.6](https://github.com/ollama/ollama/issues/10455) by blysin
- [unknown model architecture: 'qwen3'](https://github.com/ollama/ollama/issues/10454) by cam-narzt
- [GPU not being used in Linux by Ollama > 0.5.1](https://github.com/ollama/ollama/issues/10449) by leikareipa
- [Qwen 3 requires removing <think>...</think> from previous messages](https://github.com/ollama/ollama/issues/10448) by taha-yassine
- [ollama ps shows 100% on GPU VRAM, but CPU/RAM is actually being used](https://github.com/ollama/ollama/issues/10445) by samteezy
- [0.6.7-rc0 makes open-webui unable to access recent history](https://github.com/ollama/ollama/issues/10441) by scscgit
- [Granite 3.3: thinking does not work if using system prompt](https://github.com/ollama/ollama/issues/10439) by sebdotv
- [Have Ollama be able to report the status of a model loading into memory](https://github.com/ollama/ollama/issues/10438) by sudo-jake
- [Community Project: An Open-Source App Built with Ollama](https://github.com/ollama/ollama/issues/10437) by bahamutww
- ["bad manifest" name=registry.ollama.ai/library/granite3.2-vision:2b error=EOF](https://github.com/ollama/ollama/issues/10435) by somera
- [Ollama 0.6.6 memory leak](https://github.com/ollama/ollama/issues/10434) by moonflash
- [Ollama 0.6.6 memory leak with different models](https://github.com/ollama/ollama/issues/10433) by somera
- [Adding support for amd new GPUS 9070 and 9070 XT](https://github.com/ollama/ollama/issues/10430) by doomaholic
- [Regression: "runtime error: slice bounds out of range [:-1]" when using /api/embed with bge-m3 embedding model in 0.6.7-rc0 (works in 0.6.6)](https://github.com/ollama/ollama/issues/10429) by Seven-94
- [Add Kimi models](https://github.com/ollama/ollama/issues/10428) by Igorgro
- [Mix using CPU and GPU even the GTT size is enough to load the Model on GTT of iGPU of AMD Ryzen AI 395](https://github.com/ollama/ollama/issues/10427) by alexhegit
- [ollama for amd](https://github.com/ollama/ollama/issues/10426) by juca-12
- [GLM-4-0414 32B returns GGGGGG[...] on generation with prompts >=64 tokens on ROCm backend](https://github.com/ollama/ollama/issues/10424) by AdamNiederer
- [Indicate the model name in the debugging logs](https://github.com/ollama/ollama/issues/10423) by enigmadrm
- [AMD RX 6900 XT - ggml_cuda_init: failed to initialize ROCm: no ROCm-capable device is detected](https://github.com/ollama/ollama/issues/10421) by moophlo
- [Ollama 0.6.6 - Mistral-Small3.1 - Memory Leak ?](https://github.com/ollama/ollama/issues/10417) by Burnarz
- [GGML_ASSERT(talloc->buffer_id >= 0) failed](https://github.com/ollama/ollama/issues/10410) by robertmx
- [GLM-4-0414 uses the wrong template](https://github.com/ollama/ollama/issues/10408) by matteoserva
- [Upgrade Ollama Error](https://github.com/ollama/ollama/issues/10406) by MonsieurMa
- [Ollama Pull Command throwing error](https://github.com/ollama/ollama/issues/10403) by hcl-aagarwal
- [Official RTX 5090 Support](https://github.com/ollama/ollama/issues/10402) by stanblesk
- [Ollama terminal should support --help command such ollama --help or ollama run --help, to advice on next steps](https://github.com/ollama/ollama/issues/10401) by omonimus1
- [Gemma 3 vision random text](https://github.com/ollama/ollama/issues/10395) by krishna-winzo
- [Ollama since 0.6.4 + Gemma 3 27b - SIGSEGV: segmentation violation after several /api/generate](https://github.com/ollama/ollama/issues/10394) by jetnet
- [Vision - IQ3_XXS - Mistral Small 3.1 24b](https://github.com/ollama/ollama/issues/10393) by mirage335
- [Gemma3 add support for do_pan_and_scan](https://github.com/ollama/ollama/issues/10392) by wbste
- [Ollama Library Upload Fails for Big-Endian Models](https://github.com/ollama/ollama/issues/10391) by taronaeo
- [Can not read the free memory? It seems to read the all memory in machine not just assigned to the mirror？](https://github.com/ollama/ollama/issues/10389) by wangzd0209
- [Abnormal CPU/GPU Invocation in Ollama v0.6.6​](https://github.com/ollama/ollama/issues/10387) by minghua-123
- [AMD Ryzen AI 300 series not utilizing properly](https://github.com/ollama/ollama/issues/10384) by orrinwitt
- [Ollama is not utilizing GPU](https://github.com/ollama/ollama/issues/10381) by oo33shan
- [Allow Ollama to use http:// instead of https:// to connect to the registry](https://github.com/ollama/ollama/issues/10376) by Daniel-Nashed
- [Strange issue 0.6.5 & 0.6.6.: Ollama is inventing input/output (model: deepcoder)](https://github.com/ollama/ollama/issues/10375) by u1pns
- [Community Project: Lightweight React Frontend for Ollama](https://github.com/ollama/ollama/issues/10373) by cushydigit
- [[Model request] X-ALMA machine translate model good for structured or markup language](https://github.com/ollama/ollama/issues/10371) by rainbowflesh
- [Cannot find hosted documentation](https://github.com/ollama/ollama/issues/10370) by jonas-eschle
- [ollama ps runtime shows using GPU but actually logs using cpu](https://github.com/ollama/ollama/issues/10369) by liuyixia-make
- [ragflow get ollama api warn:truncating input prompt" limit=2048](https://github.com/ollama/ollama/issues/10368) by yiminghub2024
- [ollama run gemma3:4b/12b/27b crash](https://github.com/ollama/ollama/issues/10366) by yiminghub2024
- [(openshift) - pulled model in the container but the model directory is empty in openshift.](https://github.com/ollama/ollama/issues/10365) by doyoungim999
- [Broken long context performance of Gemma3-27B](https://github.com/ollama/ollama/issues/10361) by vYLQs6
- [Memory allocation or estimation problem](https://github.com/ollama/ollama/issues/10359) by apunkt
- [Allow granite lora support](https://github.com/ollama/ollama/issues/10358) by victorcasignia
- [option to select installation folder from the installer](https://github.com/ollama/ollama/issues/10356) by AlizerUncaged
- [please support OmniSQL-7B](https://github.com/ollama/ollama/issues/10355) by wolfewf
- [The 0.6.5 .tgz binary returns /404 on /models, but /api/tags works. Can you confirm it’s the correct build?](https://github.com/ollama/ollama/issues/10354) by Just-us-Crash
- [Incorrect memory allocation](https://github.com/ollama/ollama/issues/10351) by bitcandy
- [Graphical option to toggle whether ollama launches on boot](https://github.com/ollama/ollama/issues/10346) by mcandre
- [The model's memory and GPU memory usage increases](https://github.com/ollama/ollama/issues/10345) by 1556900941lizerui
- [add update cli](https://github.com/ollama/ollama/issues/10344) by hamzamg
- [Gemma 3 12b (Q4_K_M) fills system RAM despite available VRAM (OLLAMA 0.6.5)](https://github.com/ollama/ollama/issues/10341) by ALLMI78
- [Granite3.3 : thinking doesn't work if using tools](https://github.com/ollama/ollama/issues/10338) by lemassykoi
- [Add Bitnet.cpp engine](https://github.com/ollama/ollama/issues/10337) by qdrddr
- [Using Ollama + OpenWebUI on AWS Tesla T4](https://github.com/ollama/ollama/issues/10336) by Ara3096
- [Support microsoft/bitnet-b1.58-2B-4T](https://github.com/ollama/ollama/issues/10334) by liudonghua123
- [CLI: image path not recognized correctly](https://github.com/ollama/ollama/issues/10333) by mchiang0610
- [Client2 Feedback](https://github.com/ollama/ollama/issues/10331) by bmizerany
- [install TARGETS given target "ggml-cpu" which does not exist (archlinux, amd64, gfx1201)](https://github.com/ollama/ollama/issues/10330) by codeliger
- [Error when using tools: cannot unmarshal array into Go struct field .tools.function.parameters.properties.type of type string](https://github.com/ollama/ollama/issues/10328) by loudar
- [ollama ps reports wrong values (depending on num_batch?)](https://github.com/ollama/ollama/issues/10327) by ALLMI78
- [Add remote Model with local API Key (Proxy)](https://github.com/ollama/ollama/issues/10324) by 9M6
- [GPU Memory Utilization and Performance Anomalies](https://github.com/ollama/ollama/issues/10323) by ALLMI78
- [Please support MT-GPU in ollama](https://github.com/ollama/ollama/issues/10321) by BodhiHu

## 🔀 Open Pull Requests
- [lower default num parallel to 2](https://github.com/ollama/ollama/pull/10468) by drifkin
- [Use proper SVG for ollama.svg](https://github.com/ollama/ollama/pull/10466) by balcsida
- [Update README.md](https://github.com/ollama/ollama/pull/10465) by HarshNevse
- [server: add python tool parsing logic](https://github.com/ollama/ollama/pull/10453) by ParthSareen
- [convert/convert_qwen2: Fix ropescaling factor data type for Qwen2 models](https://github.com/ollama/ollama/pull/10447) by mobilemutex
- [[Docs] Update gpu.md](https://github.com/ollama/ollama/pull/10440) by ramonpaolo
- [Updated the version of golang/crypto and golang/net package to handle CVE-2025-22869, CVE-2025-22870, CVE-2025-22872](https://github.com/ollama/ollama/pull/10436) by batuhankadioglu
- [Tls x509 fix](https://github.com/ollama/ollama/pull/10431) by CupOfGeo
- [cmd: added sorting and json formatting to list and ps commands](https://github.com/ollama/ollama/pull/10425) by mrMalinka
- [Update README.md](https://github.com/ollama/ollama/pull/10420) by victor-capriles
- [model: support python tools and streaming](https://github.com/ollama/ollama/pull/10415) by ParthSareen
- [wip: write tensors in parallel](https://github.com/ollama/ollama/pull/10413) by mxyng
- [fix: multiple typos of different importancec](https://github.com/ollama/ollama/pull/10399) by crStiv
- [Add Deploy Script Signing Using SSH Private Key](https://github.com/ollama/ollama/pull/10398) by pedrolucas167
- [make systemd service conditional, only create if it doesn't exist](https://github.com/ollama/ollama/pull/10390) by gompa
- [Fixes for Mistral 3 Small](https://github.com/ollama/ollama/pull/10388) by deece
- [WIP: Qwen2.5-VL](https://github.com/ollama/ollama/pull/10385) by BruceMacD
- [Add Huggingface model card README.md (YAML) to GGUF convert](https://github.com/ollama/ollama/pull/10380) by mrutkows
- [Add link to lightweight React frontend client for Ollama](https://github.com/ollama/ollama/pull/10378) by cushydigit
- [Move quantization to new backend](https://github.com/ollama/ollama/pull/10363) by dhiltgen
- [Converter for GraniteMoE architecture](https://github.com/ollama/ollama/pull/10362) by mrutkows
- [function Pull off Registry](https://github.com/ollama/ollama/pull/10347) by pedrolucas167
- [Alphabitize the list](https://github.com/ollama/ollama/pull/10340) by jjasghar
- [Add support Intel GPU by OneApi /SYCL](https://github.com/ollama/ollama/pull/10322) by chnxq
- [server: Added Basic support for OpenAI Responses Endpoint](https://github.com/ollama/ollama/pull/10316) by RediatBrook
- [discover: Support cgroups cores and memory limitations](https://github.com/ollama/ollama/pull/10292) by SiLeader
- [Add lrc-ai-assistant to the list of community integrations in README.md](https://github.com/ollama/ollama/pull/10289) by bmachek
- [support minicpm-omni](https://github.com/ollama/ollama/pull/10280) by tc-mb
- [server: send 405 instead of 404 for unallowed methods](https://github.com/ollama/ollama/pull/10275) by drifkin
- [FreeBSD patches](https://github.com/ollama/ollama/pull/10254) by yurivict
- [fs/ggml: support for big-endian model file parsing](https://github.com/ollama/ollama/pull/10245) by taronaeo
- [Avoid restart manager](https://github.com/ollama/ollama/pull/10242) by dhiltgen
- [Update README.md](https://github.com/ollama/ollama/pull/10240) by qwerty108109
- [ggml: fix crash for array head counts](https://github.com/ollama/ollama/pull/10238) by drifkin
- [fix: variable substitution and argument passing in build scripts](https://github.com/ollama/ollama/pull/10237) by 0xsenty
- [clarify quantization behavior in docs](https://github.com/ollama/ollama/pull/10224) by thot-experiment
- [Update README.md](https://github.com/ollama/ollama/pull/10220) by qwerty108109
- [feat: capitalise ollama in ollama help description](https://github.com/ollama/ollama/pull/10203) by SwetaTanwar
- [Update README.md](https://github.com/ollama/ollama/pull/10202) by qwerty108109
- [server: do not attempt to parse offset file as gguf](https://github.com/ollama/ollama/pull/10201) by BruceMacD
- [scripts/install.sh: make curl progress bar optional](https://github.com/ollama/ollama/pull/10196) by alej0varas
- [fix: ensure log file is properly closed after logging completes](https://github.com/ollama/ollama/pull/10187) by googs1025
- [app: allow GPU vendor opt-out during install](https://github.com/ollama/ollama/pull/10186) by DimmaDont
- [Server: Enhance API/tag with Capability Information](https://github.com/ollama/ollama/pull/10174) by JasonHonKL
- [create: check architecture rather than vision.block_count when importing GGUF](https://github.com/ollama/ollama/pull/10162) by rick-github
- [discover: make unique_id check optional for AMD GPU detection](https://github.com/ollama/ollama/pull/10150) by vlttnv
- [Fix OpenAI model retrieval for models with slashes](https://github.com/ollama/ollama/pull/10147) by SplittyDev
- [chore: add miss error check](https://github.com/ollama/ollama/pull/10144) by googs1025
- [create blobs in parallel](https://github.com/ollama/ollama/pull/10135) by mxyng
- [Added ollama4j-ui](https://github.com/ollama/ollama/pull/10129) by amithkoujalgi
- [Added Emacs client package ollama-buddy to README.md](https://github.com/ollama/ollama/pull/10095) by captainflasmr
- [GraniteMoE new engine](https://github.com/ollama/ollama/pull/10079) by gabe-l-hart
- [ml: structured rope config to allow specifying context length](https://github.com/ollama/ollama/pull/10078) by BruceMacD
- [feat: enhance pull command to support pulling multiple models in one go](https://github.com/ollama/ollama/pull/10052) by pwntr
- [Adding a search command](https://github.com/ollama/ollama/pull/10046) by Tickloop
- [Mention the correct server log path for homebrew users](https://github.com/ollama/ollama/pull/10044) by fffx
- [add ollama stop all](https://github.com/ollama/ollama/pull/10043) by TommyBoiss
- [HSA_OVERRIDE_GFX_VERSION for individual GPU's](https://github.com/ollama/ollama/pull/10034) by colin-stubbs
- [Dockerfile: Don't strip the Go symbol table](https://github.com/ollama/ollama/pull/10029) by metalmatze
- [cmd: output JSON and CSV formats in the list and ps command line tool](https://github.com/ollama/ollama/pull/10020) by hopefulTex
- [server: prevent model thrashing from unset API fields](https://github.com/ollama/ollama/pull/10003) by rick-github
- [server: Improve download reliability in bandwidth-constrained environments.](https://github.com/ollama/ollama/pull/9991) by monolith-jaehoon
- [config: allow setting fixed context length](https://github.com/ollama/ollama/pull/9978) by pppy2012
- [server: support streaming near tool usage](https://github.com/ollama/ollama/pull/9973) by fizx
- [Granite new engine](https://github.com/ollama/ollama/pull/9966) by gabe-l-hart
- [`install.sh` : add `OLLAMA_INSTALL_ROCM` to make ROCM installation optional ](https://github.com/ollama/ollama/pull/9954) by SuperUserNameMan
- [fix: validate input size in parseSafetensors to prevent integer overflow](https://github.com/ollama/ollama/pull/9952) by y198nt
- [macapp/src - Changes MacOS installer to skip symlink step if CLI is already installed](https://github.com/ollama/ollama/pull/9943) by kaviraj-j
- [Limit collation 9929](https://github.com/ollama/ollama/pull/9930) by gabe-l-hart
- [fix(Fedora): install CUDA with 40 or 41 repo](https://github.com/ollama/ollama/pull/9869) by fubuloubu
- [fix(Fedora): wrong subcommand for `dnf config-manager`](https://github.com/ollama/ollama/pull/9866) by fubuloubu
- [examples clean , code optimize](https://github.com/ollama/ollama/pull/9853) by zhanluxianshen
- [fix: fixes a memory leak in bfloat16 package](https://github.com/ollama/ollama/pull/9851) by pdevine
- [Fix template processing for tool calls in /v1/chat/completions endpoint](https://github.com/ollama/ollama/pull/9834) by alejomongua
- [Rocm wsl support conflicts](https://github.com/ollama/ollama/pull/9828) by its-so-fluffy
- [Add --no-kv-offload parameter](https://github.com/ollama/ollama/pull/9751) by apt-install-coffee
- [Add benchmark cli option to Ollama](https://github.com/ollama/ollama/pull/9738) by saman-amd
- [Fix HTTP 200 handling (no Location field)](https://github.com/ollama/ollama/pull/9737) by boxjan
- [template: Improve ollama model chat template](https://github.com/ollama/ollama/pull/9735) by eugene-kamenev
- [Update README.md](https://github.com/ollama/ollama/pull/9719) by Aharon-Bensadoun
- [implement qwen2 adapter convert](https://github.com/ollama/ollama/pull/9668) by nicholaslee119
- [Vulkan support  (replacing pull/5059)](https://github.com/ollama/ollama/pull/9650) by grinco
- [server: install path](https://github.com/ollama/ollama/pull/9646) by brccabral
- [fix: skip GPU compatibility check on Windows when HSA_OVERRIDE_GFX_VE…](https://github.com/ollama/ollama/pull/9614) by cocochick
- [Fix out-of-bounds access to digest](https://github.com/ollama/ollama/pull/9609) by ac0d3r
- [feat: introduce bash shell autocompletion script and documentation](https://github.com/ollama/ollama/pull/9585) by gwpl
- [fix: return scanner error when stream connection unexpectedly disconnects](https://github.com/ollama/ollama/pull/9570) by Asutorufa
- [Add PREPEND Modelfile directive to prepend text to model responses](https://github.com/ollama/ollama/pull/9552) by ehartford
- [server: allow dynamic token generation limit with num_predict==-2](https://github.com/ollama/ollama/pull/9547) by rick-github
- [server: add num_parallel to allow per-model control](https://github.com/ollama/ollama/pull/9546) by rick-github
- [ci: use separate, faster runners for building windows releases](https://github.com/ollama/ollama/pull/9450) by jmorganca
- [Update install.sh](https://github.com/ollama/ollama/pull/9445) by JE-lee
- [Update parser.go (granite 3.2 control role support)](https://github.com/ollama/ollama/pull/9396) by XReyRobert-IBM
- [Server: Add active inference status to ollama ps ](https://github.com/ollama/ollama/pull/9392) by ankh2054
- [server: align file position to general.alignment at end of decoding.](https://github.com/ollama/ollama/pull/9368) by rick-github
- [server: Add `OLLAMA_NUM_PULL_PARTS` environment variable to reduce stall occurrences](https://github.com/ollama/ollama/pull/9321) by monolith-jaehoon
- [runner: enable returning more info from runner processing](https://github.com/ollama/ollama/pull/9282) by BruceMacD
- [server: emit load and total durations for a load](https://github.com/ollama/ollama/pull/9277) by rick-github
- [WIP: feat: add support for immutable distros and non-wheel/sudo users](https://github.com/ollama/ollama/pull/9274) by boredsquirrel
- [fix: the problem of loading models with large difference in initial and final layer sizes](https://github.com/ollama/ollama/pull/9243) by itej89

## ✅ Commits Today
- [Merge pull request #10452 from ollama/drifkin/4096-context-length](https://github.com/ollama/ollama/commit/6ec71d8fb6705d12c9bc3df3511ce9b255ee375f) by Devon Rifkin
- [config: update default context length to 4096](https://github.com/ollama/ollama/commit/44b466eeb2e42e9ce2852c69d7cddb7ebac5daf8) by Devon Rifkin
- [Merge pull request #10451 from ollama/revert-10364-drifkin/context-length](https://github.com/ollama/ollama/commit/a25f3f8260c421413cb821ba8cb338fff6b32280) by Devon Rifkin
